{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data Splitting, Subsetting, and Saving\n",
    "\n",
    "This notebook is for preparing different subsets of the whole ABEA dataset for training runs. It performs the following:\n",
    "- Reload all ABEA annotations\n",
    "- Save a df to a .JSONL file (for Doccano upload)\n",
    "- Spilts a df into 10-fold cross validation subsets and then writes them to .txt files in a given location\n",
    "- Creates subsets from the whole df baed on certain criteria e.g. \"only 1 aspect term\", or \"aspect terms where the total character count is less than 40\", ... \n",
    "\n",
    "Note:\n",
    "The original annotations are very complex where reasoning is ambiguous and the annotation lengths are highly varied, so several tests were run on different subsets of the whole dataset to test the training outcomes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast                                                              # A Python module that helps to process trees of the Python abstract syntax grammar\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to reformat data in GRACE Format\n",
    "\n",
    "def process_text(text, labels):\n",
    "    words = text.split()\n",
    "    indices = []\n",
    "    start = 0\n",
    "    for word in words:\n",
    "        end = start + len(word)\n",
    "        indices.append((start, end))\n",
    "        start = end + 1  # +1 for the space or newline character\n",
    "\n",
    "    formatted_text = []\n",
    "    # reformat the lists which are stored as strings back into list formats\n",
    "    labels = ast.literal_eval(labels)\n",
    "\n",
    "    for i, (word, (start_idx, end_idx)) in enumerate(zip(words, indices)):\n",
    "        label = \"O O O\"\n",
    "        for label_range in labels:\n",
    "            # a start index of -2 indicates that the label is \"none\"\n",
    "            if start == -2:\n",
    "                label = \"O O O\"\n",
    "            else:\n",
    "                range_start, range_end, emotion = label_range\n",
    "                if start_idx >= range_start and end_idx <= range_end:\n",
    "                    if start_idx == range_start:\n",
    "                        label = f\"B_AP {emotion.upper()} B_AP+{emotion.upper()}\"\n",
    "                    else:\n",
    "                        label = f\"I_AP {emotion.upper()} I_AP+{emotion.upper()}\"\n",
    "                    break\n",
    "        formatted_text.append(f\"{word} - - {label}\")\n",
    "\n",
    "    return formatted_text\n",
    "\n",
    "def format_dataframe(df):\n",
    "    all_formatted_texts = []\n",
    "    for _, row in df.iterrows():\n",
    "        formatted_text = process_text(row['text'], row['label'])\n",
    "        all_formatted_texts.extend(formatted_text)\n",
    "        all_formatted_texts.append(\"\")  # Empty row between tweets\n",
    "\n",
    "    return \"\\n\".join(all_formatted_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-Load All ABEA Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2625\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>message_id</th>\n",
       "      <th>label</th>\n",
       "      <th>Comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2767</td>\n",
       "      <td>Proud to receive an A+ rating from th Nevada F...</td>\n",
       "      <td>1524255702851620864</td>\n",
       "      <td>[[20, 29, 'Happiness'], [87, 112, 'Happiness']]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2768</td>\n",
       "      <td>@AnotherJay @mayor_anderson @BorisJohnson My f...</td>\n",
       "      <td>1323323443446747136</td>\n",
       "      <td>[[57, 62, 'Anger'], [225, 235, 'Anger']]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2769</td>\n",
       "      <td>I can't even: Gunfire erupts after a high scho...</td>\n",
       "      <td>1532901446114365440</td>\n",
       "      <td>[[14, 21, 'Sadness'], [81, 94, 'Sadness']]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2770</td>\n",
       "      <td>@codefknblack I had a good gun play session th...</td>\n",
       "      <td>1356204586806222848</td>\n",
       "      <td>[[27, 43, 'Happiness']]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2771</td>\n",
       "      <td>@PennySpalpeen @jenfox84 @pastebbins @LucyFan4...</td>\n",
       "      <td>1333825902220881920</td>\n",
       "      <td>[[348, 352, 'Happiness'], [408, 413, 'Happines...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    id                                               text  \\\n",
       "0           0  2767  Proud to receive an A+ rating from th Nevada F...   \n",
       "1           1  2768  @AnotherJay @mayor_anderson @BorisJohnson My f...   \n",
       "2           2  2769  I can't even: Gunfire erupts after a high scho...   \n",
       "3           3  2770  @codefknblack I had a good gun play session th...   \n",
       "4           4  2771  @PennySpalpeen @jenfox84 @pastebbins @LucyFan4...   \n",
       "\n",
       "            message_id                                              label  \\\n",
       "0  1524255702851620864    [[20, 29, 'Happiness'], [87, 112, 'Happiness']]   \n",
       "1  1323323443446747136           [[57, 62, 'Anger'], [225, 235, 'Anger']]   \n",
       "2  1532901446114365440         [[14, 21, 'Sadness'], [81, 94, 'Sadness']]   \n",
       "3  1356204586806222848                            [[27, 43, 'Happiness']]   \n",
       "4  1333825902220881920  [[348, 352, 'Happiness'], [408, 413, 'Happines...   \n",
       "\n",
       "  Comments  \n",
       "0       []  \n",
       "1       []  \n",
       "2       []  \n",
       "3       []  \n",
       "4       []  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Data/Training Data/Refined Annotations/prepared_emotions.csv\")\n",
    "print(len(df))\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n",
      "47\n"
     ]
    }
   ],
   "source": [
    "print(df['label'].dtype)\n",
    "print(len(df.loc[0, 'label']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Either turn the Label Column into a List Format or a String Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# turn into list format \n",
    "\n",
    "import ast\n",
    "\n",
    "# Convert the 'label' column from string to actual list\n",
    "df['label'] = df['label'].apply(ast.literal_eval)\n",
    "\n",
    "print(df['label'].dtype)\n",
    "# check that the label column is now in the correct list format\n",
    "print(len(df.loc[0, 'label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n"
     ]
    }
   ],
   "source": [
    "# turn into string format\n",
    "\n",
    "df['label'] = df['label'].astype(str)\n",
    "\n",
    "print(df['label'].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save DF to .JSONL File for Doccano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1524255702851620864</td>\n",
       "      <td>Proud to receive an A+ rating from th Nevada F...</td>\n",
       "      <td>[[20, 29, Happiness], [92, 112, Happiness]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1323323443446747136</td>\n",
       "      <td>@AnotherJay @mayor_anderson @BorisJohnson My f...</td>\n",
       "      <td>[[225, 235, Anger]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1532901446114365440</td>\n",
       "      <td>I can't even: Gunfire erupts after a high scho...</td>\n",
       "      <td>[[14, 21, Fear], [89, 94, Sadness]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1356204586806222848</td>\n",
       "      <td>@codefknblack I had a good gun play session th...</td>\n",
       "      <td>[[27, 43, Happiness]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1333825902220881920</td>\n",
       "      <td>@PennySpalpeen @jenfox84 @pastebbins @LucyFan4...</td>\n",
       "      <td>[[353, 357, Happiness], [386, 392, Happiness]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            message_id                                               text  \\\n",
       "0  1524255702851620864  Proud to receive an A+ rating from th Nevada F...   \n",
       "1  1323323443446747136  @AnotherJay @mayor_anderson @BorisJohnson My f...   \n",
       "2  1532901446114365440  I can't even: Gunfire erupts after a high scho...   \n",
       "3  1356204586806222848  @codefknblack I had a good gun play session th...   \n",
       "4  1333825902220881920  @PennySpalpeen @jenfox84 @pastebbins @LucyFan4...   \n",
       "\n",
       "                                            label  \n",
       "0     [[20, 29, Happiness], [92, 112, Happiness]]  \n",
       "1                             [[225, 235, Anger]]  \n",
       "2             [[14, 21, Fear], [89, 94, Sadness]]  \n",
       "3                           [[27, 43, Happiness]]  \n",
       "4  [[353, 357, Happiness], [386, 392, Happiness]]  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop all other columns\n",
    "df = df[['message_id', 'text', 'label']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"whole_dataset_labeled.jsonl\"\n",
    "# os.makedirs(os.path.dirname(filepath), exist_ok=True)\n",
    "\n",
    "with open(filepath, \"w\") as f:\n",
    "    f.write(df.to_json(orient='records', lines=True))\n",
    "    \n",
    "    # Data\\Training Data\\0 - Raw Input Data for Annotations\\2 - Annotated Data for Revision in JSONL Format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Train, Validation, Testing Split + Save to  GRACE Format\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "80% allocated to training + validation, further split this to have 90% for training and 10% for validation. This results in 72% of the data being used for training, 8% for validation, and 20% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2146\n"
     ]
    }
   ],
   "source": [
    "# optionally apply some filtering criteria\n",
    "# df = df[df['label'].apply(lambda x: len(x) == 1)]\n",
    "df = df[df['label'].apply(lambda x: sum([item[1] - item[0] for item in x]) < 30)]\n",
    "\n",
    "print(len(df))\n",
    "\n",
    "# re-convert into string format\n",
    "df['label'] = df['label'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\chris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\chris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['NNP', 'PRP$'], ['NNP', 'NN'], ['NN', 'JJ'], ['JJ'], ['PRP', 'NN']]\n",
      "2625\n",
      "1402\n"
     ]
    }
   ],
   "source": [
    "# add a column for POS tagging\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "\n",
    "# Ensure that you have the required nltk resources downloaded\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "pos = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    \n",
    "    pos_row = []\n",
    "    \n",
    "    for label in row['label']:\n",
    "\n",
    "        # Extract the aspect term using character positions\n",
    "        start, end, _ = label\n",
    "        aspect_term = row['text'][start:end+1]\n",
    "        \n",
    "        # Tokenize the aspect term\n",
    "        tokens = word_tokenize(aspect_term)\n",
    "        # POS tagging\n",
    "        tagged_tokens = nltk.pos_tag(tokens)\n",
    "        if len(tagged_tokens) > 0:\n",
    "          \n",
    "            pos_row.append(tagged_tokens[0][1])\n",
    "\n",
    "    pos.append(pos_row)\n",
    "\n",
    "print(pos[:5])\n",
    "print(len(pos))\n",
    "\n",
    "df['POS'] = pos\n",
    "\n",
    "# Define the noun tags\n",
    "noun_tags = {'NN', 'NNP', 'NNS'}\n",
    "\n",
    "# Filter rows where all POS tags are noun tags\n",
    "df = df[df['POS'].apply(lambda x: all(tag in noun_tags for tag in x))]\n",
    "\n",
    "# re-convert into string format\n",
    "df['label'] = df['label'].astype(str)\n",
    "\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>message_id</th>\n",
       "      <th>label</th>\n",
       "      <th>Comments</th>\n",
       "      <th>POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2768</td>\n",
       "      <td>@AnotherJay @mayor_anderson @BorisJohnson My f...</td>\n",
       "      <td>1323323443446747136</td>\n",
       "      <td>[[57, 62, 'Anger'], [225, 235, 'Anger']]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[NNP, NN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2772</td>\n",
       "      <td>@myhairynipples @SkySportsPL Drogba you prick</td>\n",
       "      <td>1302449973204746240</td>\n",
       "      <td>[[29, 35, 'Anger']]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[NN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2773</td>\n",
       "      <td>@SandraKobelt @MailOnline A lot more than 13, ...</td>\n",
       "      <td>1524641627184132096</td>\n",
       "      <td>[[50, 74, 'None']]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[NN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>2776</td>\n",
       "      <td>The @SDSU Police Department and San Diego Fire...</td>\n",
       "      <td>1567966037509025792</td>\n",
       "      <td>[[78, 90, 'None']]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[NN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>2777</td>\n",
       "      <td>Wind 7.6 mph SW. Barometer 1004.2 hPa, Falling...</td>\n",
       "      <td>1322973089517445120</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0    id                                               text  \\\n",
       "1            1  2768  @AnotherJay @mayor_anderson @BorisJohnson My f...   \n",
       "5            5  2772      @myhairynipples @SkySportsPL Drogba you prick   \n",
       "6            6  2773  @SandraKobelt @MailOnline A lot more than 13, ...   \n",
       "9            9  2776  The @SDSU Police Department and San Diego Fire...   \n",
       "10          10  2777  Wind 7.6 mph SW. Barometer 1004.2 hPa, Falling...   \n",
       "\n",
       "             message_id                                     label Comments  \\\n",
       "1   1323323443446747136  [[57, 62, 'Anger'], [225, 235, 'Anger']]       []   \n",
       "5   1302449973204746240                       [[29, 35, 'Anger']]       []   \n",
       "6   1524641627184132096                        [[50, 74, 'None']]       []   \n",
       "9   1567966037509025792                        [[78, 90, 'None']]       []   \n",
       "10  1322973089517445120                                        []       []   \n",
       "\n",
       "          POS  \n",
       "1   [NNP, NN]  \n",
       "5        [NN]  \n",
       "6        [NN]  \n",
       "9        [NN]  \n",
       "10         []  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 896\n",
      "Validation set size: 225\n",
      "Testing set size: 281\n"
     ]
    }
   ],
   "source": [
    "# Split into 80% for training + validation and 20% for testing\n",
    "train_val_df, test_df = train_test_split(df, test_size=0.2, random_state=42, shuffle=True)\n",
    "# train_val_df, test_df = train_test_split(df, test_size=0.2, random_state=35, shuffle=True)\n",
    "\n",
    "# Split the 80% into training and validation (90% for training, 10% for validation)\n",
    "train_df, val_df = train_test_split(train_val_df, test_size=0.2, random_state=1, shuffle=True)\n",
    " \n",
    "# Now you have three subsets\n",
    "print(f\"Training set size: {len(train_df)}\")\n",
    "print(f\"Validation set size: {len(val_df)}\")\n",
    "print(f\"Testing set size: {len(test_df)}\")\n",
    "\n",
    "# refromat into GRACE format (one word per row with label)\n",
    "formatted_train = format_dataframe(train_df)\n",
    "formatted_trial = format_dataframe(val_df)\n",
    "formatted_test = format_dataframe(test_df)\n",
    "\n",
    "\n",
    "# Write the output to a .txt file\n",
    "# file_train = f\"GRACE/data/testing_train.txt\"\n",
    "# file_trial = f\"GRACE/data/testing_trial.txt\"\n",
    "# file_test = f\"GRACE/data/testing_test.gold.txt\"\n",
    "file_train = f\"GRACE/data/refined_nouns_train.txt\"\n",
    "file_trial = f\"GRACE/data/refined_nouns_trial.txt\"\n",
    "file_test = f\"GRACE/data/refined_nouns_test.gold.txt\"\n",
    "\n",
    "with open(file_train, 'w') as file:\n",
    "    file.write('-DOCSTART-\\n\\n')\n",
    "    file.write(formatted_train)\n",
    "\n",
    "with open(file_trial, 'w') as file:\n",
    "    file.write('-DOCSTART-\\n\\n')\n",
    "    file.write(formatted_trial)\n",
    "\n",
    "with open(file_test, 'w') as file:\n",
    "    file.write('-DOCSTART-\\n\\n')\n",
    "    file.write(formatted_test)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10-fold Cross Validation Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare KFold with 10 splits\n",
    "kf = KFold(n_splits=10, random_state=32, shuffle=True)\n",
    "\n",
    "# This dictionary will store the indices for each fold\n",
    "fold_indices = {'train': [], 'trial': [], 'test': []}\n",
    "\n",
    "# Split the data into folds and collect the indices\n",
    "for fold, (train_val_index, test_index) in enumerate(kf.split(df)):\n",
    "    # Here we further split the train_val set into train and trial(validation)\n",
    "    # We'll take 90% of the train_val set as train and 10% as trial\n",
    "    train_val_split = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "    train_index, trial_index = next(train_val_split.split(train_val_index))\n",
    "    \n",
    "    # Actually getting the indices of train and trial from the main df\n",
    "    train_indices = df.iloc[train_val_index].iloc[train_index].index\n",
    "    trial_indices = df.iloc[train_val_index].iloc[trial_index].index\n",
    "    \n",
    "    # Save the indices in the dictionary\n",
    "    fold_indices['train'].append(train_indices)\n",
    "    fold_indices['trial'].append(trial_indices)\n",
    "    fold_indices['test'].append(test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tTrain: 2125,\tTrial: 237,\tTest:263\n",
      "1:\tTrain: 2125,\tTrial: 237,\tTest:263\n",
      "2:\tTrain: 2125,\tTrial: 237,\tTest:263\n",
      "3:\tTrain: 2125,\tTrial: 237,\tTest:263\n",
      "4:\tTrain: 2125,\tTrial: 237,\tTest:263\n",
      "5:\tTrain: 2126,\tTrial: 237,\tTest:262\n",
      "6:\tTrain: 2126,\tTrial: 237,\tTest:262\n",
      "7:\tTrain: 2126,\tTrial: 237,\tTest:262\n",
      "8:\tTrain: 2126,\tTrial: 237,\tTest:262\n",
      "9:\tTrain: 2126,\tTrial: 237,\tTest:262\n"
     ]
    }
   ],
   "source": [
    "# dictionary to hold the subset dataframes for each fold.\n",
    "fold_dataframes = {\n",
    "    'train': [],\n",
    "    'trial': [],\n",
    "    'test': []\n",
    "}\n",
    "\n",
    "# For each fold create subset dataframes\n",
    "for fold in range(10):\n",
    "    train_indices = fold_indices['train'][fold]\n",
    "    trial_indices = fold_indices['trial'][fold]\n",
    "    test_indices = fold_indices['test'][fold]\n",
    "\n",
    "    # Extract the subsets from the DataFrame\n",
    "    train_df = df.loc[train_indices]\n",
    "    trial_df = df.loc[trial_indices]\n",
    "    test_df = df.loc[test_indices]\n",
    "\n",
    "    # Append the subsets to the fold_dataframes dictionary\n",
    "    fold_dataframes['train'].append(train_df)\n",
    "    fold_dataframes['trial'].append(trial_df)\n",
    "    fold_dataframes['test'].append(test_df)\n",
    "\n",
    "    \n",
    "for i in range(10):\n",
    "    # Get the DataFrames for this fold\n",
    "    train_df = fold_dataframes['train'][i]\n",
    "    trial_df = fold_dataframes['trial'][i]\n",
    "    test_df = fold_dataframes['test'][i]\n",
    "\n",
    "    print(f\"{i}:\\tTrain: {len(train_df)},\\tTrial: {len(trial_df)},\\tTest:{len(test_df)}\")\n",
    "\n",
    "    # refromat into GRACE format (one word per row with label)\n",
    "    formatted_train = format_dataframe(train_df)\n",
    "    formatted_trial = format_dataframe(trial_df)\n",
    "    formatted_test = format_dataframe(test_df)\n",
    "\n",
    "\n",
    "    # Write the output to a .txt file\n",
    "    file_train = f\"GRACE/data/same_split_as_absa/ten_fold_abea_w_none_clean/abea_w_none_clean_{i}_train.txt\"\n",
    "    file_trial = f\"GRACE/data/same_split_as_absa/ten_fold_abea_w_none_clean/abea_w_none_clean_{i}_trial.txt\"\n",
    "    file_test = f\"GRACE/data/same_split_as_absa/ten_fold_abea_w_none_clean/abea_w_none_clean_{i}_test.gold.txt\"\n",
    "\n",
    "    with open(file_train, 'w') as file:\n",
    "        file.write('-DOCSTART-\\n\\n')\n",
    "        file.write(formatted_train)\n",
    "\n",
    "    with open(file_trial, 'w') as file:\n",
    "        file.write('-DOCSTART-\\n\\n')\n",
    "        file.write(formatted_trial)\n",
    "\n",
    "    with open(file_test, 'w') as file:\n",
    "        file.write('-DOCSTART-\\n\\n')\n",
    "        file.write(formatted_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Subsets for further Testing with Tweets that have Short Aspect Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "# Convert the 'label' column from string to actual list\n",
    "df['label'] = df['label'].apply(ast.literal_eval)\n",
    "\n",
    "# check that the label column is now in the correct list format\n",
    "print(len(df.loc[0, 'label']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subset 1: Only one aspect term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1956\n"
     ]
    }
   ],
   "source": [
    "# create subset that filters for only those rows where there is just one labelled item\n",
    "subset1 = df[df['label'].apply(lambda x: len(x) == 1)]\n",
    "print(len(subset1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split proportions\n",
    "test_size = 0.1  # 10% for testing\n",
    "trial_size = 0.1  # 10% of the train_val for trial (validation)\n",
    "\n",
    "# First split: Separate test set from train_val set\n",
    "subset1_train_val, subset1_test = train_test_split(subset1, test_size=test_size, random_state=32, shuffle=True)\n",
    "\n",
    "# Second split: Separate trial (validation) set from training set\n",
    "adjusted_trial_size = trial_size / (1 - test_size)\n",
    "subset1_train, subset1_trial = train_test_split(subset1_train_val, test_size=adjusted_trial_size, random_state=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subset 2: Aspect terms where the total character count amounts to less than 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2479\n"
     ]
    }
   ],
   "source": [
    "subset2 = df[df['label'].apply(lambda x: sum([item[1] - item[0] for item in x]) < 40)]\n",
    "print(len(subset2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split proportions\n",
    "test_size = 0.1  # 10% for testing\n",
    "trial_size = 0.1  # 10% of the train_val for trial (validation)\n",
    "\n",
    "# First split: Separate test set from train_val set\n",
    "subset2_train_val, subset2_test = train_test_split(subset2, test_size=test_size, random_state=32, shuffle=True)\n",
    "\n",
    "# Second split: Separate trial (validation) set from training set\n",
    "adjusted_trial_size = trial_size / (1 - test_size)\n",
    "subset2_train, subset2_trial = train_test_split(subset2_train_val, test_size=adjusted_trial_size, random_state=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196\n",
      "196\n",
      "1564\n"
     ]
    }
   ],
   "source": [
    "print(len(subset1_test))\n",
    "print(len(subset1_trial))\n",
    "print(len(subset1_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subset 3: Aspect Terms where the total character count amounts to less than 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023\n"
     ]
    }
   ],
   "source": [
    "subset3 = df[df['label'].apply(lambda x: sum([item[1] - item[0] for item in x]) < 20)]\n",
    "print(len(subset3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203\n",
      "203\n",
      "1617\n"
     ]
    }
   ],
   "source": [
    "# split proportions\n",
    "test_size = 0.1  # 10% for testing\n",
    "trial_size = 0.1  # 10% of the train_val for trial (validation)\n",
    "\n",
    "# First split: Separate test set from train_val set\n",
    "subset3_train_val, subset3_test = train_test_split(subset3, test_size=test_size, random_state=32, shuffle=True)\n",
    "\n",
    "# Second split: Separate trial (validation) set from training set\n",
    "adjusted_trial_size = trial_size / (1 - test_size)\n",
    "subset3_train, subset3_trial = train_test_split(subset3_train_val, test_size=adjusted_trial_size, random_state=1, shuffle=True)\n",
    "\n",
    "print(len(subset3_test))\n",
    "print(len(subset3_trial))\n",
    "print(len(subset3_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subset 4: Aspect Terms where the total character count amounts to less than 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1485\n"
     ]
    }
   ],
   "source": [
    "subset4 = df[df['label'].apply(lambda x: sum([item[1] - item[0] for item in x]) < 10)]\n",
    "print(len(subset4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149\n",
      "149\n",
      "1187\n"
     ]
    }
   ],
   "source": [
    "# split proportions\n",
    "test_size = 0.1  # 10% for testing\n",
    "trial_size = 0.1  # 10% of the train_val for trial (validation)\n",
    "\n",
    "# First split: Separate test set from train_val set\n",
    "subset4_train_val, subset4_test = train_test_split(subset4, test_size=test_size, random_state=32, shuffle=True)\n",
    "\n",
    "# Second split: Separate trial (validation) set from training set\n",
    "adjusted_trial_size = trial_size / (1 - test_size)\n",
    "subset4_train, subset4_trial = train_test_split(subset4_train_val, test_size=adjusted_trial_size, random_state=1, shuffle=True)\n",
    "\n",
    "print(len(subset4_test))\n",
    "print(len(subset4_trial))\n",
    "print(len(subset4_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subset5: Remove the \"none\" rows from subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>message_id</th>\n",
       "      <th>label</th>\n",
       "      <th>Comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25334</td>\n",
       "      <td>Proud to receive an A+ rating from th Nevada F...</td>\n",
       "      <td>1524255702851620864</td>\n",
       "      <td>[[20, 29, Happiness], [92, 112, Happiness]]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25335</td>\n",
       "      <td>@AnotherJay @mayor_anderson @BorisJohnson My f...</td>\n",
       "      <td>1323323443446747136</td>\n",
       "      <td>[[225, 235, Anger]]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25336</td>\n",
       "      <td>I can't even: Gunfire erupts after a high scho...</td>\n",
       "      <td>1532901446114365440</td>\n",
       "      <td>[[14, 21, Fear], [89, 94, Sadness]]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25337</td>\n",
       "      <td>@codefknblack I had a good gun play session th...</td>\n",
       "      <td>1356204586806222848</td>\n",
       "      <td>[[27, 43, Happiness]]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25338</td>\n",
       "      <td>@PennySpalpeen @jenfox84 @pastebbins @LucyFan4...</td>\n",
       "      <td>1333825902220881920</td>\n",
       "      <td>[[353, 357, Happiness], [386, 392, Happiness]]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25339</td>\n",
       "      <td>@myhairynipples @SkySportsPL Drogba you prick</td>\n",
       "      <td>1302449973204746240</td>\n",
       "      <td>[[29, 35, Anger]]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>25340</td>\n",
       "      <td>@SandraKobelt @MailOnline A lot more than 13, ...</td>\n",
       "      <td>1524641627184132096</td>\n",
       "      <td>[[-2, -1, none]]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>25341</td>\n",
       "      <td>Give this a watch well worth it informative an...</td>\n",
       "      <td>1323368847748063232</td>\n",
       "      <td>[[5, 9, Happiness]]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>25342</td>\n",
       "      <td>Can you tell we miss DofE? Getting outside one...</td>\n",
       "      <td>1322993372878020608</td>\n",
       "      <td>[[21, 25, Happiness], [109, 131, Happiness]]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>25343</td>\n",
       "      <td>The @SDSU Police Department and San Diego Fire...</td>\n",
       "      <td>1567966037509025792</td>\n",
       "      <td>[[191, 199, Fear]]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                               text  \\\n",
       "0  25334  Proud to receive an A+ rating from th Nevada F...   \n",
       "1  25335  @AnotherJay @mayor_anderson @BorisJohnson My f...   \n",
       "2  25336  I can't even: Gunfire erupts after a high scho...   \n",
       "3  25337  @codefknblack I had a good gun play session th...   \n",
       "4  25338  @PennySpalpeen @jenfox84 @pastebbins @LucyFan4...   \n",
       "5  25339      @myhairynipples @SkySportsPL Drogba you prick   \n",
       "6  25340  @SandraKobelt @MailOnline A lot more than 13, ...   \n",
       "7  25341  Give this a watch well worth it informative an...   \n",
       "8  25342  Can you tell we miss DofE? Getting outside one...   \n",
       "9  25343  The @SDSU Police Department and San Diego Fire...   \n",
       "\n",
       "            message_id                                           label  \\\n",
       "0  1524255702851620864     [[20, 29, Happiness], [92, 112, Happiness]]   \n",
       "1  1323323443446747136                             [[225, 235, Anger]]   \n",
       "2  1532901446114365440             [[14, 21, Fear], [89, 94, Sadness]]   \n",
       "3  1356204586806222848                           [[27, 43, Happiness]]   \n",
       "4  1333825902220881920  [[353, 357, Happiness], [386, 392, Happiness]]   \n",
       "5  1302449973204746240                               [[29, 35, Anger]]   \n",
       "6  1524641627184132096                                [[-2, -1, none]]   \n",
       "7  1323368847748063232                             [[5, 9, Happiness]]   \n",
       "8  1322993372878020608    [[21, 25, Happiness], [109, 131, Happiness]]   \n",
       "9  1567966037509025792                              [[191, 199, Fear]]   \n",
       "\n",
       "  Comments  \n",
       "0       []  \n",
       "1       []  \n",
       "2       []  \n",
       "3       []  \n",
       "4       []  \n",
       "5       []  \n",
       "6       []  \n",
       "7       []  \n",
       "8       []  \n",
       "9       []  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1790\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>message_id</th>\n",
       "      <th>label</th>\n",
       "      <th>Comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25334</td>\n",
       "      <td>Proud to receive an A+ rating from th Nevada F...</td>\n",
       "      <td>1524255702851620864</td>\n",
       "      <td>[[20, 29, Happiness], [92, 112, Happiness]]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25335</td>\n",
       "      <td>@AnotherJay @mayor_anderson @BorisJohnson My f...</td>\n",
       "      <td>1323323443446747136</td>\n",
       "      <td>[[225, 235, Anger]]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25336</td>\n",
       "      <td>I can't even: Gunfire erupts after a high scho...</td>\n",
       "      <td>1532901446114365440</td>\n",
       "      <td>[[14, 21, Fear], [89, 94, Sadness]]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25337</td>\n",
       "      <td>@codefknblack I had a good gun play session th...</td>\n",
       "      <td>1356204586806222848</td>\n",
       "      <td>[[27, 43, Happiness]]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25338</td>\n",
       "      <td>@PennySpalpeen @jenfox84 @pastebbins @LucyFan4...</td>\n",
       "      <td>1333825902220881920</td>\n",
       "      <td>[[353, 357, Happiness], [386, 392, Happiness]]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                               text  \\\n",
       "0  25334  Proud to receive an A+ rating from th Nevada F...   \n",
       "1  25335  @AnotherJay @mayor_anderson @BorisJohnson My f...   \n",
       "2  25336  I can't even: Gunfire erupts after a high scho...   \n",
       "3  25337  @codefknblack I had a good gun play session th...   \n",
       "4  25338  @PennySpalpeen @jenfox84 @pastebbins @LucyFan4...   \n",
       "\n",
       "            message_id                                           label  \\\n",
       "0  1524255702851620864     [[20, 29, Happiness], [92, 112, Happiness]]   \n",
       "1  1323323443446747136                             [[225, 235, Anger]]   \n",
       "2  1532901446114365440             [[14, 21, Fear], [89, 94, Sadness]]   \n",
       "3  1356204586806222848                           [[27, 43, Happiness]]   \n",
       "4  1333825902220881920  [[353, 357, Happiness], [386, 392, Happiness]]   \n",
       "\n",
       "  Comments  \n",
       "0       []  \n",
       "1       []  \n",
       "2       []  \n",
       "3       []  \n",
       "4       []  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset5 = df[~df['label'].apply(lambda x: [-2, -1, 'none'] in x)]\n",
    "# subset5 = subset5[subset5['label'].apply(lambda x: sum([item[1] - item[0] for item in x]) < 30)]\n",
    "\n",
    "print(len(subset5))\n",
    "subset5.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135\n",
      "135\n",
      "1072\n"
     ]
    }
   ],
   "source": [
    "# split proportions\n",
    "test_size = 0.1  # 10% for testing\n",
    "trial_size = 0.1  # 10% of the train_val for trial (validation)\n",
    "\n",
    "# First split: Separate test set from train_val set\n",
    "subset5_train_val, subset5_test = train_test_split(subset5, test_size=test_size, random_state=32, shuffle=True)\n",
    "\n",
    "# Second split: Separate trial (validation) set from training set\n",
    "adjusted_trial_size = trial_size / (1 - test_size)\n",
    "subset5_train, subset5_trial = train_test_split(subset5_train_val, test_size=adjusted_trial_size, random_state=1, shuffle=True)\n",
    "\n",
    "print(len(subset5_test))\n",
    "print(len(subset5_trial))\n",
    "print(len(subset5_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subset 6: Without None Category and less than 30 Chars for AT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1342\n",
      "135\n",
      "135\n",
      "1072\n"
     ]
    }
   ],
   "source": [
    "subset5 = df[~df['label'].apply(lambda x: [-2, -1, 'none'] in x)]\n",
    "subset5 = subset5[subset5['label'].apply(lambda x: sum([item[1] - item[0] for item in x]) < 30)]\n",
    "\n",
    "print(len(subset5))\n",
    "# subset5.head()\n",
    "\n",
    "# split proportions\n",
    "test_size = 0.1  # 10% for testing\n",
    "trial_size = 0.1  # 10% of the train_val for trial (validation)\n",
    "\n",
    "# First split: Separate test set from train_val set\n",
    "subset5_train_val, subset5_test = train_test_split(subset5, test_size=test_size, random_state=32, shuffle=True)\n",
    "\n",
    "# Second split: Separate trial (validation) set from training set\n",
    "adjusted_trial_size = trial_size / (1 - test_size)\n",
    "subset5_train, subset5_trial = train_test_split(subset5_train_val, test_size=adjusted_trial_size, random_state=1, shuffle=True)\n",
    "\n",
    "print(len(subset5_test))\n",
    "print(len(subset5_trial))\n",
    "print(len(subset5_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentence-Level Emotion Subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A subset of the whole df with just the rows where the label contains only one emotion. That can be the case if there is just one label like this: ```[[20, 29, 'Happiness']]```, or if there are several labels, but they all have the same emotion, like this: ```[[20, 29, 'Happiness'], [92, 112, 'Happiness']]```, but NOT if there is more than one emotion, like this: ```[[14, 21, 'Fear'], [89, 94, 'Sadness'], [353, 357, 'Happiness']]```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>message_id</th>\n",
       "      <th>label</th>\n",
       "      <th>Comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25334</td>\n",
       "      <td>Proud to receive an A+ rating from th Nevada F...</td>\n",
       "      <td>1524255702851620864</td>\n",
       "      <td>[[20, 29, Happiness], [92, 112, Happiness]]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25335</td>\n",
       "      <td>@AnotherJay @mayor_anderson @BorisJohnson My f...</td>\n",
       "      <td>1323323443446747136</td>\n",
       "      <td>[[225, 235, Anger]]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25336</td>\n",
       "      <td>I can't even: Gunfire erupts after a high scho...</td>\n",
       "      <td>1532901446114365440</td>\n",
       "      <td>[[14, 21, Fear], [89, 94, Sadness]]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25337</td>\n",
       "      <td>@codefknblack I had a good gun play session th...</td>\n",
       "      <td>1356204586806222848</td>\n",
       "      <td>[[27, 43, Happiness]]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25338</td>\n",
       "      <td>@PennySpalpeen @jenfox84 @pastebbins @LucyFan4...</td>\n",
       "      <td>1333825902220881920</td>\n",
       "      <td>[[353, 357, Happiness], [386, 392, Happiness]]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                               text  \\\n",
       "0  25334  Proud to receive an A+ rating from th Nevada F...   \n",
       "1  25335  @AnotherJay @mayor_anderson @BorisJohnson My f...   \n",
       "2  25336  I can't even: Gunfire erupts after a high scho...   \n",
       "3  25337  @codefknblack I had a good gun play session th...   \n",
       "4  25338  @PennySpalpeen @jenfox84 @pastebbins @LucyFan4...   \n",
       "\n",
       "            message_id                                           label  \\\n",
       "0  1524255702851620864     [[20, 29, Happiness], [92, 112, Happiness]]   \n",
       "1  1323323443446747136                             [[225, 235, Anger]]   \n",
       "2  1532901446114365440             [[14, 21, Fear], [89, 94, Sadness]]   \n",
       "3  1356204586806222848                           [[27, 43, Happiness]]   \n",
       "4  1333825902220881920  [[353, 357, Happiness], [386, 392, Happiness]]   \n",
       "\n",
       "  Comments  \n",
       "0       []  \n",
       "1       []  \n",
       "2       []  \n",
       "3       []  \n",
       "4       []  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>message_id</th>\n",
       "      <th>label</th>\n",
       "      <th>Comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25334</td>\n",
       "      <td>Proud to receive an A+ rating from th Nevada F...</td>\n",
       "      <td>1524255702851620864</td>\n",
       "      <td>[[20, 29, Happiness], [92, 112, Happiness]]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25335</td>\n",
       "      <td>@AnotherJay @mayor_anderson @BorisJohnson My f...</td>\n",
       "      <td>1323323443446747136</td>\n",
       "      <td>[[225, 235, Anger]]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25336</td>\n",
       "      <td>I can't even: Gunfire erupts after a high scho...</td>\n",
       "      <td>1532901446114365440</td>\n",
       "      <td>[[14, 21, Fear], [89, 94, Sadness]]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25337</td>\n",
       "      <td>@codefknblack I had a good gun play session th...</td>\n",
       "      <td>1356204586806222848</td>\n",
       "      <td>[[27, 43, Happiness]]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25338</td>\n",
       "      <td>@PennySpalpeen @jenfox84 @pastebbins @LucyFan4...</td>\n",
       "      <td>1333825902220881920</td>\n",
       "      <td>[[353, 357, Happiness], [386, 392, Happiness]]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                               text  \\\n",
       "0  25334  Proud to receive an A+ rating from th Nevada F...   \n",
       "1  25335  @AnotherJay @mayor_anderson @BorisJohnson My f...   \n",
       "2  25336  I can't even: Gunfire erupts after a high scho...   \n",
       "3  25337  @codefknblack I had a good gun play session th...   \n",
       "4  25338  @PennySpalpeen @jenfox84 @pastebbins @LucyFan4...   \n",
       "\n",
       "            message_id                                           label  \\\n",
       "0  1524255702851620864     [[20, 29, Happiness], [92, 112, Happiness]]   \n",
       "1  1323323443446747136                             [[225, 235, Anger]]   \n",
       "2  1532901446114365440             [[14, 21, Fear], [89, 94, Sadness]]   \n",
       "3  1356204586806222848                           [[27, 43, Happiness]]   \n",
       "4  1333825902220881920  [[353, 357, Happiness], [386, 392, Happiness]]   \n",
       "\n",
       "  Comments  \n",
       "0       []  \n",
       "1       []  \n",
       "2       []  \n",
       "3       []  \n",
       "4       []  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_emotion_if_single(labels):\n",
    "    # Check if the labels list is empty\n",
    "    if not labels:\n",
    "        print('no label')\n",
    "        return None  # Return None for empty label lists\n",
    "\n",
    "    # Extract all emotions from the labels\n",
    "    emotions = [label[2] for label in labels]\n",
    "    \n",
    "    # Check if all elements in the emotions list are the same\n",
    "    if all(emotion == emotions[0] for emotion in emotions):\n",
    "        return emotions[0]  # Return the emotion name if all are the same\n",
    "    else:\n",
    "        return None  # Return None if there are different emotions\n",
    "\n",
    "df_single_emotion = df\n",
    "df_single_emotion.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no label\n",
      "no label\n",
      "no label\n",
      "no label\n",
      "no label\n",
      "no label\n",
      "no label\n"
     ]
    }
   ],
   "source": [
    "df_single_emotion['sent_level_emotion'] = df_single_emotion['label'].apply(get_emotion_if_single)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2544\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>message_id</th>\n",
       "      <th>label</th>\n",
       "      <th>Comments</th>\n",
       "      <th>sent_level_emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25334</td>\n",
       "      <td>Proud to receive an A+ rating from th Nevada F...</td>\n",
       "      <td>1524255702851620864</td>\n",
       "      <td>[[20, 29, Happiness], [92, 112, Happiness]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25335</td>\n",
       "      <td>@AnotherJay @mayor_anderson @BorisJohnson My f...</td>\n",
       "      <td>1323323443446747136</td>\n",
       "      <td>[[225, 235, Anger]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25337</td>\n",
       "      <td>@codefknblack I had a good gun play session th...</td>\n",
       "      <td>1356204586806222848</td>\n",
       "      <td>[[27, 43, Happiness]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25338</td>\n",
       "      <td>@PennySpalpeen @jenfox84 @pastebbins @LucyFan4...</td>\n",
       "      <td>1333825902220881920</td>\n",
       "      <td>[[353, 357, Happiness], [386, 392, Happiness]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25339</td>\n",
       "      <td>@myhairynipples @SkySportsPL Drogba you prick</td>\n",
       "      <td>1302449973204746240</td>\n",
       "      <td>[[29, 35, Anger]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                               text  \\\n",
       "0  25334  Proud to receive an A+ rating from th Nevada F...   \n",
       "1  25335  @AnotherJay @mayor_anderson @BorisJohnson My f...   \n",
       "3  25337  @codefknblack I had a good gun play session th...   \n",
       "4  25338  @PennySpalpeen @jenfox84 @pastebbins @LucyFan4...   \n",
       "5  25339      @myhairynipples @SkySportsPL Drogba you prick   \n",
       "\n",
       "            message_id                                           label  \\\n",
       "0  1524255702851620864     [[20, 29, Happiness], [92, 112, Happiness]]   \n",
       "1  1323323443446747136                             [[225, 235, Anger]]   \n",
       "3  1356204586806222848                           [[27, 43, Happiness]]   \n",
       "4  1333825902220881920  [[353, 357, Happiness], [386, 392, Happiness]]   \n",
       "5  1302449973204746240                               [[29, 35, Anger]]   \n",
       "\n",
       "  Comments sent_level_emotion  \n",
       "0       []          Happiness  \n",
       "1       []              Anger  \n",
       "3       []          Happiness  \n",
       "4       []          Happiness  \n",
       "5       []              Anger  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_single_emotion = df_single_emotion[df_single_emotion['sent_level_emotion'].notna()]\n",
    "print(len(df_single_emotion))\n",
    "df_single_emotion.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>sent_level_emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25334</td>\n",
       "      <td>Proud to receive an A+ rating from th Nevada F...</td>\n",
       "      <td>Happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25335</td>\n",
       "      <td>@AnotherJay @mayor_anderson @BorisJohnson My f...</td>\n",
       "      <td>Anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25337</td>\n",
       "      <td>@codefknblack I had a good gun play session th...</td>\n",
       "      <td>Happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25338</td>\n",
       "      <td>@PennySpalpeen @jenfox84 @pastebbins @LucyFan4...</td>\n",
       "      <td>Happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25339</td>\n",
       "      <td>@myhairynipples @SkySportsPL Drogba you prick</td>\n",
       "      <td>Anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>25340</td>\n",
       "      <td>@SandraKobelt @MailOnline A lot more than 13, ...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>25341</td>\n",
       "      <td>Give this a watch well worth it informative an...</td>\n",
       "      <td>Happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>25342</td>\n",
       "      <td>Can you tell we miss DofE? Getting outside one...</td>\n",
       "      <td>Happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>25343</td>\n",
       "      <td>The @SDSU Police Department and San Diego Fire...</td>\n",
       "      <td>Fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>25344</td>\n",
       "      <td>Wind 7.6 mph SW. Barometer 1004.2 hPa, Falling...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>25345</td>\n",
       "      <td>Bang average, second best and just waiting to ...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>25346</td>\n",
       "      <td>@LBC what a load of bollocks. \\nWhoever though...</td>\n",
       "      <td>Anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>25347</td>\n",
       "      <td>@_BillieBelieves As a parent that made me cry ...</td>\n",
       "      <td>Happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>25348</td>\n",
       "      <td>@illi4141 @OborneTweets @oflynnsocial What doe...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>25349</td>\n",
       "      <td>@BandQ Hi, my mother bought a bin and realised...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>25350</td>\n",
       "      <td>For what could quite conceivably be my last co...</td>\n",
       "      <td>Happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>25351</td>\n",
       "      <td>@whiteycpfc @RedNBlueArmy1 @WhyteleafeEagle @a...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>25352</td>\n",
       "      <td>@premierinn\\nSent you a dm hours ago, any chan...</td>\n",
       "      <td>Anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>25353</td>\n",
       "      <td>@bike_pat hi there !! I work at @EHSBramley wi...</td>\n",
       "      <td>Happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>25354</td>\n",
       "      <td>Today is the day! BHFD &amp; BHCPR will be teachin...</td>\n",
       "      <td>Happiness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                               text  \\\n",
       "0   25334  Proud to receive an A+ rating from th Nevada F...   \n",
       "1   25335  @AnotherJay @mayor_anderson @BorisJohnson My f...   \n",
       "3   25337  @codefknblack I had a good gun play session th...   \n",
       "4   25338  @PennySpalpeen @jenfox84 @pastebbins @LucyFan4...   \n",
       "5   25339      @myhairynipples @SkySportsPL Drogba you prick   \n",
       "6   25340  @SandraKobelt @MailOnline A lot more than 13, ...   \n",
       "7   25341  Give this a watch well worth it informative an...   \n",
       "8   25342  Can you tell we miss DofE? Getting outside one...   \n",
       "9   25343  The @SDSU Police Department and San Diego Fire...   \n",
       "10  25344  Wind 7.6 mph SW. Barometer 1004.2 hPa, Falling...   \n",
       "11  25345  Bang average, second best and just waiting to ...   \n",
       "12  25346  @LBC what a load of bollocks. \\nWhoever though...   \n",
       "13  25347  @_BillieBelieves As a parent that made me cry ...   \n",
       "14  25348  @illi4141 @OborneTweets @oflynnsocial What doe...   \n",
       "15  25349  @BandQ Hi, my mother bought a bin and realised...   \n",
       "16  25350  For what could quite conceivably be my last co...   \n",
       "17  25351  @whiteycpfc @RedNBlueArmy1 @WhyteleafeEagle @a...   \n",
       "18  25352  @premierinn\\nSent you a dm hours ago, any chan...   \n",
       "19  25353  @bike_pat hi there !! I work at @EHSBramley wi...   \n",
       "20  25354  Today is the day! BHFD & BHCPR will be teachin...   \n",
       "\n",
       "   sent_level_emotion  \n",
       "0           Happiness  \n",
       "1               Anger  \n",
       "3           Happiness  \n",
       "4           Happiness  \n",
       "5               Anger  \n",
       "6                none  \n",
       "7           Happiness  \n",
       "8           Happiness  \n",
       "9                Fear  \n",
       "10               none  \n",
       "11               none  \n",
       "12              Anger  \n",
       "13          Happiness  \n",
       "14               none  \n",
       "15               none  \n",
       "16          Happiness  \n",
       "17               none  \n",
       "18              Anger  \n",
       "19          Happiness  \n",
       "20          Happiness  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_single_emotion = df_single_emotion[['id', 'text', 'sent_level_emotion']]\n",
    "df_single_emotion.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_single_emotion.to_csv(\"Data/Training Data/2 - Data Reformatted and Split for Training/sent_level_emotions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Count the occurrences of each emotion in the 'sent_level_emotion' column\n",
    "emotion_counts = df_single_emotion['sent_level_emotion'].value_counts()\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))  # Set the figure size for better readability\n",
    "emotion_counts.plot(kind='bar', color='skyblue')  # Create a bar chart\n",
    "plt.title('Emotion Counts in Sentence-level Dataset')  # Title of the chart\n",
    "plt.xlabel('Emotion')  # X-axis label\n",
    "plt.ylabel('Count')  # Y-axis label\n",
    "plt.xticks(rotation=45)  # Rotate the X-axis labels for better readability\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reformat and save Subsets to GRACE Repo for Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output written to GRACE/data/subsets/subset2_train.txt\n",
      "Output written to GRACE/data/subsets/subset2_trial.txt\n",
      "Output written to GRACE/data/subsets/subset2_test.gold.txt\n",
      "Output written to GRACE/data/subsets/subset1_train.txt\n",
      "Output written to GRACE/data/subsets/subset1_trial.txt\n",
      "Output written to GRACE/data/subsets/subset1_test.gold.txt\n"
     ]
    }
   ],
   "source": [
    "subset_dfs = [subset2_train, subset2_trial, subset2_test, subset1_train, subset1_trial, subset1_test]\n",
    "filenames = ['subset2_train', 'subset2_trial', 'subset2_test.gold', 'subset1_train', 'subset1_trial', 'subset1_test.gold']\n",
    "\n",
    "# Process the DataFrame\n",
    "for i in range(len(subset_dfs)):\n",
    "    \n",
    "    # load current df\n",
    "    df_cur = subset_dfs[i]\n",
    "    \n",
    "    # turn the list format in the \"label\" column back into string for processing\n",
    "    df_cur['label'] = df_cur['label'].apply(str)\n",
    "\n",
    "    # reformat for GRACE format\n",
    "    formatted_data = format_dataframe(df_cur)\n",
    "\n",
    "    # Write the output to a .txt file\n",
    "    output_file_path = f\"GRACE/data/subsets/{filenames[i]}.txt\"\n",
    "    with open(output_file_path, 'w') as file:\n",
    "        file.write('-DOCSTART-\\n\\n')\n",
    "        file.write(formatted_data)\n",
    "\n",
    "    print(f\"Output written to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output written to GRACE/data/subsets/subset3_train.txt\n",
      "Output written to GRACE/data/subsets/subset3_trial.txt\n",
      "Output written to GRACE/data/subsets/subset3_test.gold.txt\n"
     ]
    }
   ],
   "source": [
    "subset_dfs = [subset3_train, subset3_trial, subset3_test]\n",
    "filenames = ['subset3_train', 'subset3_trial', 'subset3_test.gold']\n",
    "\n",
    "# Process the DataFrame\n",
    "for i in range(len(subset_dfs)):\n",
    "    \n",
    "    # load current df\n",
    "    df_cur = subset_dfs[i]\n",
    "    \n",
    "    # turn the list format in the \"label\" column back into string for processing\n",
    "    df_cur['label'] = df_cur['label'].apply(str)\n",
    "\n",
    "    # reformat for GRACE format\n",
    "    formatted_data = format_dataframe(df_cur)\n",
    "\n",
    "    # Write the output to a .txt file\n",
    "    output_file_path = f\"GRACE/data/subsets/{filenames[i]}.txt\"\n",
    "    with open(output_file_path, 'w') as file:\n",
    "        file.write('-DOCSTART-\\n\\n')\n",
    "        file.write(formatted_data)\n",
    "\n",
    "    print(f\"Output written to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output written to GRACE/data/subsets/subset4_train.txt\n",
      "Output written to GRACE/data/subsets/subset4_trial.txt\n",
      "Output written to GRACE/data/subsets/subset4_test.gold.txt\n"
     ]
    }
   ],
   "source": [
    "subset_dfs = [subset4_train, subset4_trial, subset4_test]\n",
    "filenames = ['subset4_train', 'subset4_trial', 'subset4_test.gold']\n",
    "\n",
    "# Process the DataFrame\n",
    "for i in range(len(subset_dfs)):\n",
    "    \n",
    "    # load current df\n",
    "    df_cur = subset_dfs[i]\n",
    "    \n",
    "    # turn the list format in the \"label\" column back into string for processing\n",
    "    df_cur['label'] = df_cur['label'].apply(str)\n",
    "\n",
    "    # reformat for GRACE format\n",
    "    formatted_data = format_dataframe(df_cur)\n",
    "\n",
    "    # Write the output to a .txt file\n",
    "    output_file_path = f\"GRACE/data/subsets/{filenames[i]}.txt\"\n",
    "    with open(output_file_path, 'w') as file:\n",
    "        file.write('-DOCSTART-\\n\\n')\n",
    "        file.write(formatted_data)\n",
    "\n",
    "    print(f\"Output written to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output written to GRACE/data/subsets/subset6_train.txt\n",
      "Output written to GRACE/data/subsets/subset6_trial.txt\n",
      "Output written to GRACE/data/subsets/subset6_test.gold.txt\n"
     ]
    }
   ],
   "source": [
    "subset_dfs = [subset5_train, subset5_trial, subset5_test]\n",
    "filenames = ['subset6_train', 'subset6_trial', 'subset6_test.gold']\n",
    "\n",
    "# Process the DataFrame\n",
    "for i in range(len(subset_dfs)):\n",
    "    \n",
    "    # load current df\n",
    "    df_cur = subset_dfs[i]\n",
    "    \n",
    "    # turn the list format in the \"label\" column back into string for processing\n",
    "    df_cur['label'] = df_cur['label'].apply(str)\n",
    "\n",
    "    # reformat for GRACE format\n",
    "    formatted_data = format_dataframe(df_cur)\n",
    "\n",
    "    # Write the output to a .txt file\n",
    "    output_file_path = f\"GRACE/data/subsets/{filenames[i]}.txt\"\n",
    "    with open(output_file_path, 'w') as file:\n",
    "        file.write('-DOCSTART-\\n\\n')\n",
    "        file.write(formatted_data)\n",
    "\n",
    "    print(f\"Output written to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 fold cross validation split for nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to read the GRACE-formatted txt file into a df with a 'text' and 'label' column.\n",
    "def grace_format_to_df_cols(txt_path):\n",
    "\n",
    "    with open(txt_path, 'r') as file:\n",
    "        file_content = file.read()\n",
    "    \n",
    "    content_without_docstart = file_content.split('\\n', 1)[1]\n",
    "\n",
    "    # Split the content based on empty lines to get each sequence\n",
    "    sequences = [seq.strip() for seq in content_without_docstart.split('\\n\\n') if seq.strip()]\n",
    "\n",
    "    texts_labels = [process_sequence(seq) for seq in sequences]\n",
    "    texts, labels = zip(*texts_labels)  # Unzip the texts and labels\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'text': texts,\n",
    "        'label': labels\n",
    "    })\n",
    "\n",
    "    return df\n",
    "\n",
    "# function to process each of the sequences\n",
    "def process_sequence(seq):\n",
    "    words = []\n",
    "    labels = []\n",
    "    char_index = 0  # Start from the first character\n",
    "    in_label = False\n",
    "    label_start = 0\n",
    "    label_sentiment = ''\n",
    "\n",
    "    for line in seq.split('\\n'):\n",
    "        parts = line.split()\n",
    "        if len(parts) < 2:  # Skip empty lines or lines without tags\n",
    "            continue\n",
    "        word, tag = parts[0], parts[-1]\n",
    "        words.append(word)\n",
    "\n",
    "        # If this word starts a new label\n",
    "        if 'B_AP' in tag:\n",
    "            if in_label:  # End the previous label if starting a new one\n",
    "                labels.append([label_start, char_index - 1, label_sentiment])\n",
    "            in_label = True\n",
    "            label_start = char_index\n",
    "            # Determine the sentiment\n",
    "            if 'FEAR' in tag:\n",
    "                label_sentiment = 'FEAR'\n",
    "            elif 'NONE' in tag:\n",
    "                label_sentiment = 'NONE'\n",
    "            elif 'HAPPINESS' in tag:\n",
    "                label_sentiment = 'HAPPINESS'\n",
    "            elif 'ANGER' in tag:\n",
    "                label_sentiment = 'ANGER'\n",
    "            elif 'SADNESS' in tag:\n",
    "                label_sentiment = 'SADNESS'\n",
    "\n",
    "        # If this word is not part of a label or starts a new label\n",
    "        if 'B_AP' not in tag and 'I_AP' not in tag and in_label:\n",
    "            labels.append([label_start, char_index - 1, label_sentiment])\n",
    "            in_label = False\n",
    "\n",
    "        char_index += len(word) + 1  # Update character index for next word, adding 1 for the space\n",
    "\n",
    "    # If the last label goes till the end of the sequence\n",
    "    if in_label:\n",
    "        labels.append([label_start, char_index - 1, label_sentiment])\n",
    "\n",
    "    return ' '.join(words), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n",
      "2592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_63448\\1448659103.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  abea_nouns['label'] = abea_nouns['label'].astype(str)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>everybody n they momma parked on the side of c...</td>\n",
       "      <td>[[0, 9, 'SADNESS'], [12, 22, 'SADNESS'], [73, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Just posted a photo @ Dylans , George Street ,...</td>\n",
       "      <td>[[14, 19, 'NONE']]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fabulous to be cycling ( virtually ) up the Pa...</td>\n",
       "      <td>[[15, 22, 'HAPPINESS'], [44, 60, 'HAPPINESS'],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Memorials , delegations , &amp; flyering today in ...</td>\n",
       "      <td>[[71, 80, 'SADNESS'], [85, 93, 'SADNESS'], [10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@realsb4feelings Nothing to do with flu and co...</td>\n",
       "      <td>[[36, 39, 'ANGER'], [44, 58, 'ANGER']]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ironically beautiful scene at Yosemite with a ...</td>\n",
       "      <td>[[21, 26, 'HAPPINESS'], [30, 38, 'HAPPINESS'],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>@MercedesAMGF1 You guys are just outstanding e...</td>\n",
       "      <td>[[15, 23, 'HAPPINESS'], [111, 118, 'HAPPINESS'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>@Mobile_Dom Gee , lucky you ! I was so close y...</td>\n",
       "      <td>[[24, 27, 'HAPPINESS'], [76, 82, 'SADNESS']]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Firmino from not scoring to not creating . . . .</td>\n",
       "      <td>[[0, 7, 'SADNESS']]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>@LcfcSpencerr Never met a Leicester fan ever ....</td>\n",
       "      <td>[[26, 39, 'NONE'], [91, 95, 'ANGER'], [107, 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LA-West Structure Fire reported at Speedway / ...</td>\n",
       "      <td>[[8, 22, 'NONE']]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>These are raw photos from our drive out of Yos...</td>\n",
       "      <td>[[14, 20, 'FEAR'], [130, 135, 'FEAR'], [198, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>@KarenWhiteFood Pat with seasoned flour and pa...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Just posted a photo @ London , Unιted Kingdom .</td>\n",
       "      <td>[[14, 19, 'NONE']]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>This condition was identified by Dr Sue Swedo ...</td>\n",
       "      <td>[[5, 14, 'FEAR'], [33, 45, 'HAPPINESS'], [54, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  \\\n",
       "0   everybody n they momma parked on the side of c...   \n",
       "1   Just posted a photo @ Dylans , George Street ,...   \n",
       "2   Fabulous to be cycling ( virtually ) up the Pa...   \n",
       "3   Memorials , delegations , & flyering today in ...   \n",
       "4   @realsb4feelings Nothing to do with flu and co...   \n",
       "5   Ironically beautiful scene at Yosemite with a ...   \n",
       "6   @MercedesAMGF1 You guys are just outstanding e...   \n",
       "7   @Mobile_Dom Gee , lucky you ! I was so close y...   \n",
       "8    Firmino from not scoring to not creating . . . .   \n",
       "9   @LcfcSpencerr Never met a Leicester fan ever ....   \n",
       "10  LA-West Structure Fire reported at Speedway / ...   \n",
       "11  These are raw photos from our drive out of Yos...   \n",
       "12  @KarenWhiteFood Pat with seasoned flour and pa...   \n",
       "13    Just posted a photo @ London , Unιted Kingdom .   \n",
       "14  This condition was identified by Dr Sue Swedo ...   \n",
       "\n",
       "                                                label  \n",
       "0   [[0, 9, 'SADNESS'], [12, 22, 'SADNESS'], [73, ...  \n",
       "1                                  [[14, 19, 'NONE']]  \n",
       "2   [[15, 22, 'HAPPINESS'], [44, 60, 'HAPPINESS'],...  \n",
       "3   [[71, 80, 'SADNESS'], [85, 93, 'SADNESS'], [10...  \n",
       "4              [[36, 39, 'ANGER'], [44, 58, 'ANGER']]  \n",
       "5   [[21, 26, 'HAPPINESS'], [30, 38, 'HAPPINESS'],...  \n",
       "6   [[15, 23, 'HAPPINESS'], [111, 118, 'HAPPINESS'...  \n",
       "7        [[24, 27, 'HAPPINESS'], [76, 82, 'SADNESS']]  \n",
       "8                                 [[0, 7, 'SADNESS']]  \n",
       "9   [[26, 39, 'NONE'], [91, 95, 'ANGER'], [107, 11...  \n",
       "10                                  [[8, 22, 'NONE']]  \n",
       "11  [[14, 20, 'FEAR'], [130, 135, 'FEAR'], [198, 2...  \n",
       "12                                                 []  \n",
       "13                                 [[14, 19, 'NONE']]  \n",
       "14  [[5, 14, 'FEAR'], [33, 45, 'HAPPINESS'], [54, ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# absa needs to be read properly from the GRACE formatting so that it can be converted to a df\n",
    "file_path = 'GRACE/data/same_split_as_absa/abea_w_none_clean_trial.txt'\n",
    "abea_trial = grace_format_to_df_cols(file_path)\n",
    "file_path = 'GRACE/data/same_split_as_absa/abea_w_none_clean_train.txt'\n",
    "abea_train = grace_format_to_df_cols(file_path)\n",
    "file_path = 'GRACE/data/same_split_as_absa/abea_w_none_clean_test.gold.txt'\n",
    "abea_test = grace_format_to_df_cols(file_path)\n",
    "\n",
    "concatenated = pd.concat([abea_trial, abea_train, abea_test], ignore_index=True)\n",
    "abea_nouns = concatenated.drop_duplicates(subset=['text'])\n",
    "\n",
    "# turn into string format\n",
    "\n",
    "abea_nouns['label'] = abea_nouns['label'].astype(str)\n",
    "\n",
    "print(abea_nouns['label'].dtype)\n",
    "\n",
    "print(len(abea_nouns))\n",
    "abea_nouns.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, train_test_split\n",
    "\n",
    "# Prepare KFold with 10 splits\n",
    "kf = KFold(n_splits=10, random_state=32, shuffle=True)\n",
    "\n",
    "# This dictionary will store the indices for each fold\n",
    "fold_indices = {'train': [], 'trial': [], 'test': []}\n",
    "\n",
    "# Split the data into folds and collect the indices\n",
    "for fold, (train_val_test_index, test_index) in enumerate(kf.split(abea_nouns)):\n",
    "    # Split the train_val_test set into 80% train/validation and 20% test\n",
    "    train_val_index, test_index = train_test_split(train_val_test_index, test_size=0.2, random_state=fold)\n",
    "\n",
    "    # Further split the train_val set into 70% train and 10% validation\n",
    "    train_index, trial_index = train_test_split(train_val_index, test_size=0.125, random_state=fold)\n",
    "\n",
    "    # Get the actual indices from the data\n",
    "    train_indices = abea_nouns.iloc[train_index].index\n",
    "    trial_indices = abea_nouns.iloc[trial_index].index\n",
    "    test_indices = abea_nouns.iloc[test_index].index\n",
    "\n",
    "    # Save the indices in the dictionary\n",
    "    fold_indices['train'].append(train_indices)\n",
    "    fold_indices['trial'].append(trial_indices)\n",
    "    fold_indices['test'].append(test_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tTrain: 1631,\tTrial: 234,\tTest: 467\n",
      "1:\tTrain: 1631,\tTrial: 234,\tTest: 467\n",
      "2:\tTrain: 1632,\tTrial: 234,\tTest: 467\n",
      "3:\tTrain: 1632,\tTrial: 234,\tTest: 467\n",
      "4:\tTrain: 1632,\tTrial: 234,\tTest: 467\n",
      "5:\tTrain: 1632,\tTrial: 234,\tTest: 467\n",
      "6:\tTrain: 1632,\tTrial: 234,\tTest: 467\n",
      "7:\tTrain: 1632,\tTrial: 234,\tTest: 467\n",
      "8:\tTrain: 1632,\tTrial: 234,\tTest: 467\n",
      "9:\tTrain: 1632,\tTrial: 234,\tTest: 467\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Dictionary to hold the subset dataframes for each fold\n",
    "fold_dataframes = {\n",
    "    'train': [],\n",
    "    'trial': [],\n",
    "    'test': []\n",
    "}\n",
    "\n",
    "# For each fold, create subset dataframes\n",
    "for fold in range(10):\n",
    "    train_indices = fold_indices['train'][fold]\n",
    "    trial_indices = fold_indices['trial'][fold]\n",
    "    test_indices = fold_indices['test'][fold]\n",
    "\n",
    "    # Extract the subsets from the DataFrame\n",
    "    train_df = abea_nouns.loc[train_indices]\n",
    "    trial_df = abea_nouns.loc[trial_indices]\n",
    "    test_df = abea_nouns.loc[test_indices]\n",
    "\n",
    "    # Append the subsets to the fold_dataframes dictionary\n",
    "    fold_dataframes['train'].append(train_df)\n",
    "    fold_dataframes['trial'].append(trial_df)\n",
    "    fold_dataframes['test'].append(test_df)\n",
    "\n",
    "# Save the data for each fold\n",
    "for i in range(10):\n",
    "    # Get the DataFrames for this fold\n",
    "    train_df = fold_dataframes['train'][i]\n",
    "    trial_df = fold_dataframes['trial'][i]\n",
    "    test_df = fold_dataframes['test'][i]\n",
    "\n",
    "    print(f\"{i}:\\tTrain: {len(train_df)},\\tTrial: {len(trial_df)},\\tTest: {len(test_df)}\")\n",
    "\n",
    "    # Reformat into GRACE format (one word per row with label)\n",
    "    formatted_train = format_dataframe(train_df)\n",
    "    formatted_trial = format_dataframe(trial_df)\n",
    "    formatted_test = format_dataframe(test_df)\n",
    "\n",
    "    # Write the output to a .txt file\n",
    "    file_train = f\"GRACE/data/same_split_as_absa/ten_fold_abea_w_none_clean/abea_w_none_clean_{i}_train.txt\"\n",
    "    file_trial = f\"GRACE/data/same_split_as_absa/ten_fold_abea_w_none_clean/abea_w_none_clean_{i}_trial.txt\"\n",
    "    file_test = f\"GRACE/data/same_split_as_absa/ten_fold_abea_w_none_clean/abea_w_none_clean_{i}_test.gold.txt\"\n",
    "\n",
    "    with open(file_train, 'w') as file:\n",
    "        file.write('-DOCSTART-\\n\\n')\n",
    "        file.write(formatted_train)\n",
    "\n",
    "    with open(file_trial, 'w') as file:\n",
    "        file.write('-DOCSTART-\\n\\n')\n",
    "        file.write(formatted_trial)\n",
    "\n",
    "    with open(file_test, 'w') as file:\n",
    "        file.write('-DOCSTART-\\n\\n')\n",
    "        file.write(formatted_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "absa-application",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
